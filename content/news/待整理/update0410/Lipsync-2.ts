export const Lipsync2Content = `
# 前沿动态

0408

官方文档：https://docs.sync.so/introduction

**Sync Labs发布Lipsync-2:全球首个零-shot的嘴型同步模型无需训练支持嘴型同步控制**

![img_v3_02l5_e5f2c1a8-f9f9-4dc7-aeea-36cdc5b99e5g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/Ai_Newsimg_v3_02l5_e5f2c1a8-f9f9-4dc7-aeea-36cdc5b99e5g.jpg)

Sync Labs 发布 Lipsync-2 ，全球首个零-shot的嘴型同步模型，它能在没有额外训练或微调的情况下，保留说话者独特的风格。

Lipsync-2在模型不仅在现实主义、表现力、控制力、质量和速度方面有显著提升，还引入了风格保留和温度控制等新功能，使用户能够根据需求定制同步效果。适用于多种内容类型，包括真人视频、动画以及AI生成的视频，具备极高的灵活性和适应性。

Lipsync-2 是“零样本”（zero-shot）技术的升级版，它不用事先针对某个特定的人或声音训练，就能直接用在任何人身上。

例如：你拍了个视频，但想让里面的人说点别的话，或者把英语换成中文，Lipsync-2 就能帮你调整嘴型，让它看起来像是真的一样。

**它为什么特别？**

- **不用训练**：不像老技术需要先喂一堆数据给 AI，Lipsync-2 直接拿来就能用，省时间。
- **细节牛**：它能看懂视频里的人怎么说话，然后模仿得很像，不只是简单地动嘴。
- **效果自然**：以前的工具可能会让嘴型看起来很机械，Lipsync-2 做得更像真人，连细微表情都抓得住。
- **用途广**：可以用来做视频翻译、动画配音、广告创意，甚至随便玩玩都行。

**Lipsync-2在多方面进行了提升，包括：**

- 现实主义：更真实的嘴型同步。
- 表现力：更丰富的情感表现。
- 控制力：用户能够更精细地控制嘴型同步效果。
- 质量：更高的画面和声音质量。
- 速度：更快的生成速度。
- **风格保留**：Lipsync-2能够学习说话者的风格，保持其在不同语言下的发音特点。例如，尼古拉斯·凯奇的说话风格在多种语言中都能保留。
- 新增功能：**温度控制**，即控制嘴型同步的表现力，用户可以选择保持简洁或增加更多表达。该功能目前还在私密测试版中，逐步向付费用户开放。
- **支持内容类型**：Lipsync-2可以无缝地应用于真人动作、动画或AI生成的内容。
- 大笑、尖叫或耳语都能很好的适应
- 多人说话也能全部搞定
- 不同的语言，相同的说话风格，无需训练。
- LipSync-2 在准确性、风格和表达方面表现出色

`