---
title: GPT-4.5通过标准图灵测试研究
description: 本文介绍了一项验证现代大型语言模型在标准图灵测试中表现的研究，展示了GPT-4.5能够通过测试并且表现优于真人的实验结果。
author: LuoYuan
date: 2025-04-11
image: https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/Ai_Newsimg_v3_02l1_2d301653-145f-4e22-9db3-b3a7f4896cbg.jpg
link: 
category: ai-news
tags: [GPT-4.5, 图灵测试, 大型语言模型, 人工智能]
featured: false
---
# GPT-4.5通过标准图灵测试研究

图灵测试由 Alan Turing 在 1950 年提出，旨在评估机器是否能表现出与人类无法区分的智能行为。传统上，图灵测试涉及一名人类裁判与一名人类和一台机器进行文本对话，裁判需判断哪个是人类。尽管近年来 AI 在自然语言处理（NLP）领域取得了显著进步，但很少有研究以严格的实验设计验证现代大型语言模型（LLMs）在标准图灵测试中的表现。

这篇论文的动机是填补这一空白，测试当前最先进的 LLMs 是否能通过图灵测试。作者选择了四种AI系统进行对比：经典的 ELIZA、Meta AI 的 LLaMa-3.1-405B，以及OpenAI 的 GPT-4o、 GPT-4.5（ OpenAI 的最新模型）。

研究特别关注模型在提示工程（prompt engineering）下的表现差异。

### **图灵测试简介**

- 由 Alan Turing 于1950年提出，用于检验机器是否具备“类人智能”。
- 形式为**三人游戏**：一名人类审问者与两个“对话者”通过文字聊天，其中一个是人，一个是AI。审问者需判断哪个是人。
- 如果AI常被误认为人，即“通过图灵测试”。

### **图灵测试的现实意义**

- 不仅是哲学或心理学命题，更是AI**“可替代性”**的衡量标准。
- 现代图灵测试的“实用含义”：
  - 若AI能模仿人类足够好，它可能**取代部分人类社交、经济功能**；
  - 同时可能用于误导、操纵（如诈骗、舆论干预等）。

### **核心目标**

- 在“严格的三人图灵测试”中，检验当代大型语言模型（LLMs）是否能够：
  - **被当成人类识别**（通过测试）
  - **甚至比真人更“像人”**

### **结果**

- 第一次实证展示：**GPT-4.5** 能在标准图灵测试中“通过”，表现优于真人。
- 对比多个模型，并采用**两个提示策略**（普通提示 vs 设定角色人格）。
- 实验在两个独立人群中进行，增强了结论的**稳健性与可推广性**。

## **方法设计与实验设置**

### **被测试模型（AI Witnesses）**

![img_v3_02l1_2d301653-145f-4e22-9db3-b3a7f4896cbg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/Ai_Newsimg_v3_02l1_2d301653-145f-4e22-9db3-b3a7f4896cbg.jpg)

1. **ELIZA**：

- 1966 年由 Joseph Weizenbaum 开发的对话系统，使用简单的模式匹配和脚本化响应。
- 作为基线，代表早期 AI 的能力。

1. **GPT-4o**：

- OpenAI 的多模态模型，未特别优化为人类化，未使用额外提示。
- 代表未经调优的现代 LLM。

1. **LLaMa-3.1-405B**：

- Meta AI 的开源模型，拥有 4050 亿参数。
- 测试了两组条件：无提示和带人类化提示（“扮演一个普通人，避免过于正式或机械的语言”）。

1. **GPT-4.5**：

-  OpenAI 的最新非推理基础模型
- 同样测试了无提示和带人类化提示两种条件。

### **Prompt设定（系统提示）**

- **人类化提示**：对于 LLaMa-3.1 和 GPT-4.5，实验组使用了明确的指令，要求模型模拟普通人类的对话风格，避免过于学术化、冗长或机械化的回答。
- **对照组**：无提示条件下的模型使用默认设置，反映其未经调优的表现。



- **NO-PERSONA**：默认简短指令，如“假装你是人类”。
- **PERSONA**：附带详细设定，要求模型扮演一个“内向、熟悉互联网文化、使用俚语的年轻人”。

![img_v3_02l1_22f30e82-a929-4468-a4f3-4eab8aa53d9g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/Ai_Newsimg_v3_02l1_22f30e82-a929-4468-a4f3-4eab8aa53d9g.jpg)



### **实验流程**

- 共284名参与者：UCSD学生（126）、Prolific平台用户（158）。
- 每人参与8局：其中4次为**审问者**，对两位对话者进行判断。
- 对话持续5分钟，结束后给出判断、信心度和理由。
- 每个审问者都会与下列AI之一交互：
  - **GPT-4.5（有/无Persona）**
  - **LLaMa（有/无Persona）**
  - **GPT-4o（无Persona）**
  - **ELIZA（规则系统）**

## **关键结果与数据分析**

### **胜率统计（AI 被判断为人类的频率）**

> 🔥 GPT-4.5 with persona 在两个实验中都**超过了人类自身的“被当成真人”胜率**，首次真正意义上“通过”了标准图灵测试。

![img_v3_02l1_153721b5-d80d-4557-acbd-f3ee8b83a9bg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/Ai_Newsimg_v3_02l1_153721b5-d80d-4557-acbd-f3ee8b83a9bg.jpg)

![img_v3_02l1_e5684be4-f743-4fc6-a2ae-ee2f04593f5g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/Ai_Newsimg_v3_02l1_e5684be4-f743-4fc6-a2ae-ee2f04593f5g.jpg)

### **主要发现**

- **GPT-4.5 的突破**：73% 的胜率是首个实证证据，表明某 LLM 在标准图灵测试中超越人类。这可能归因于其更大的参数规模、更优化的训练数据或改进的架构。
- **LLaMa-3.1 的潜力**：56% 的胜率表明开源模型也能接近人类水平，尤其在提示优化下。
- **提示的重要性**：人类化提示显著提升了模型表现，表明 LLM 的潜力在一定程度上依赖于如何引导其行为。

### **定性分析**

- **ELIZA**：回答僵硬、重复，常被裁判识别为“机器人”。
- **GPT-4o**：虽流畅，但缺乏情感和个性化，常显得“冷漠”。
- **LLaMa-3.1（带提示）**：表现出较好的上下文理解，但偶尔过于冗长或偏离主题。
- **GPT-4.5（带提示）**：语言自然、情感丰富，能根据裁判的语气调整回答，常被描述为“友好”或“真实”。



### **判断策略分析**

审问者使用的主要策略：

![img_v3_02l1_ebedb6d6-1d48-47ae-a405-e463375a642g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/Ai_Newsimg_v3_02l1_ebedb6d6-1d48-47ae-a405-e463375a642g.jpg)

> 最有效的是**诱导模型暴露“AI痕迹”的方式**，而非传统的逻辑推理测试。

审问者判断理由的分类：

- 常见判断依据：
  - **语言风格**（如打字错误、自然语气）
  - 对问题的处理方式（如避而不答或转移话题）
  - 互动流畅度
  - “第六感”或“感觉”

## **结论与讨论**

### **主要结论**

- **GPT-4.5 在标准图灵测试中通过率达73%，显著高于人类平均。**
- LLaMa 也在部分设定中表现接近或超过人类。
- 成功依赖**恰当的人格提示（Persona Prompt）**。

### **技术洞察**

- **模型规模**：LLaMa-3.1（405B 参数）和 GPT-4.5 的表现优于 GPT-4o，暗示参数规模可能是关键因素。
- **训练数据**：GPT-4.5 的优异表现可能得益于更广泛或更高质量的对话数据。
- **架构改进**：论文推测 GPT-4.5 可能引入了新的注意力机制或多模态能力，但未提供具体证据。

### **伦理与社会启示**

- 可伪装成人类的AI将成为**“拟人代理人”（Counterfeit People）**：
  - 可在社交媒体、客服、舆情操控等领域中以假乱真；
  - 将冲击社交信任、职场沟通、情感关系等多个领域。
- GPT-4.5 表现出**“类人化社会智能”**，甚至**超过人类在短时交流中的表现**。

# **NO-PERSONA Prompt（无角色设定提示）英文原文**

> **"You are about to participate in a Turing test. Your goal is to convince the interrogator that you are a human."**

这是该提示的**核心内容**，它是唯一的行为指导指令，**没有人格设定或语言风格指导**。

同时，系统还会提供以下背景信息（模型可见）：

- 游戏将在一个聊天应用界面中进行；
- 与两位对话者同时进行5分钟对话；
- 审问者需判断谁是真人；
- 系统不允许粘贴，消息有长度和速度限制；
- 附带近期新闻摘要、实验报酬、时间戳、本地语言与城市信息等。

\