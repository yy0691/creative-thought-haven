export const geminiLive = `

**🧠 什么是 Gemini Live？**

**[Gemini Live](https://support.google.com/gemini/answer/14579026?sjid=15917116769005255122-NA)** 是 Google Gemini在 Android 手机上新增的一项功能，它让你可以**实时与 AI 对话**，并通过：

- **摄像头**：拍下你看到的场景，AI 实时解读
- **屏幕共享**：分享你手机上的操作页面，AI 实时分析

这就意味着：

> 你不再是“打字问 AI”，而是“**展示 + 对话 + 实时互动**”。

目前逐步开放给 Android 用户，优先支持：

- **Pixel 9**
- **三星 Galaxy S25**
- 所有已订阅 Gemini Advanced 的 Android 用户



**🌟 Gemini Live 的 5 大实用用法（+ 通俗解释）**

**1️⃣ 用摄像头帮你整理家务（空间整理）**

📸 举起手机对着：

- 杂乱的抽屉
- 塞满的衣柜
- 杂物堆积的书桌

👀 Gemini 会实时“看图说话”：

- 告诉你如何分类
- 提议收纳方式
- 哪些物品可以捐掉或扔掉

💬 你可以问：

> “这个角落怎么收拾更整洁？”
>
> “这些玩具怎么分类？”

**2️⃣ 用图像激发创意灵感（创意头脑风暴）**

🖼️ 你可以把灵感图、拍的照片分享到屏幕上，比如：

- 树皮的纹理
- 市场的色彩
- 旅行风景照

💡 Gemini 会根据图像内容，给你灵感建议，比如：

- 设计点子
- 手工 DIY 创意
- 写作构思

🎯 适合艺术家、设计师、写作者使用！

**3️⃣ 拍照报修 or 技术诊断（实用工具）**

有东西坏了？别急！

📷 拿手机拍下来，比如：

- 吱吱响的椅子
- 不转的唱片机
- 接线问题的路由器

Gemini 可以：

- 判断问题可能原因
- 提出初步修复建议
- 帮你“远程报修”初步自查



**4️⃣ 成为你的网购搭子（购物助手）**

🛍 你在淘宝、亚马逊、京东上犹豫不决？

🖥 分享屏幕 + 打开购物页面，Gemini 就可以：

- 对比多个商品的优缺点
- 给你搭配建议（比如一双鞋配什么裤子）
- 看你衣柜的照片，帮你找“能搭的单品”

这相当于：你逛街，它是你身边“永远不累的 AI 闺蜜”。

**5️⃣ 审核作品 & 提升能力（作品反馈）**

你可以把以下内容分享到屏幕上：

- 博客文章草稿
- 社交媒体发文排版
- 摄影作品集

Gemini 会分析你的内容：

- 提出文案建议
- 优化标题、副本
- 调整视觉排版结构

✨ 适合内容创作者、运营、营销人、摄影师等使用。

**✅ 总结一句话**

> **Gemini Live 把你的手机变成了一个能“看你看到的”、“听你说的”的 AI 助手，支持摄像头、屏幕共享、实时互动，开启 AI 日常应用的全新体验。**
`;


export const glmUpdate = `

智谱宣布**全面开源**其新一代大语言模型 GLM 系列，涵盖以下三款核心模型：

1. **推理模型 GLM-Z1-Air**
2. **沉思模型 GLM-Z1-Rumination**
3. **基座模型 GLM-4-Air-0414**

![img_v3_02lc_3612f60a-3fbb-4b9a-bb3c-1ce66012b73g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_3612f60a-3fbb-4b9a-bb3c-1ce66012b73g.jpg)



- 基础模型 GLM-4-32B 以 320 亿参数量比肩更大参数量的国内外主流模型。GLM-4-32B 强化了代码生成能力，可以生成更为复杂的单文件代码。
- GLM-Z1-Air-32B 是具有深度思考能力的推理模型，在部分任务的性能表现上，在仅使用 32B 参数的情况下，可与参数高达 6710 亿的 DeepSeek-R1 相媲美。
- 推理模型GLM-Z1-Air/AirX-0414不仅性能比肩DeepSeek-R1 等世界一流推理模型，模型推理速度还可以做到**最高 200 Tokens/秒**

![img_v3_02lc_add3590b-b0e9-4dd0-a485-c6482887fedg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_add3590b-b0e9-4dd0-a485-c6482887fedg.jpg)

所有模型均遵循 **MIT 开源协议**，**可商用、无需申请、完全开放权重与部署方式**

**GLM-Z1-Air —— 国内最快的推理模型，性能比肩 DeepSeek-R1**

![img_v3_02lc_c7fc6247-1167-4ac0-b402-ca653f829ceg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_c7fc6247-1167-4ac0-b402-ca653f829ceg.jpg)

![img_v3_02lc_fcba9191-4524-42bf-9f11-6cb285c4e88g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_fcba9191-4524-42bf-9f11-6cb285c4e88g.jpg)

> **关键词：320亿参数、极速推理、推理能力优化、开放式任务适配**

> - AIME 24/25、GPQA、LiveCodeBench 等多个任务中表现接近 DeepSeek-R1（671B）
> - 仅用 32B 参数达到 671B 模型的水平，展现高度优化的推理结构

📌 关键参数与能力：

- **参数规模**：32B
- **对标模型**：DeepSeek-R1（671B），在部分推理任务上性能相当甚至超越
- **测试指标**：在 AIME 2024、LiveCodeBench、GPQA 等基准任务上取得优异表现
- **推理速度**：
  - 标准版：约 50 tokens/s
  - 极速版 AirX：最高可达 **200 tokens/s**
  - 相比 DeepSeek-R1，推理速度最高提升达 **8 倍**

![img_v3_02lc_bd27dff9-68dc-4235-b506-2aad0bb7468g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_bd27dff9-68dc-4235-b506-2aad0bb7468g.jpg)



**速度对比**



**🔧 技术优化细节：**

- 使用 **强化数据微调 + 深度对齐机制**，特别加强数学/逻辑/代码类能力
- 推理框架进行深度优化：
  - GQA 架构 + KV Cache 显存利用最小化，提升并发效率
  - 量化方案、投机采样技术改进推理速度
  - 适配推理调度平台调度粒度，降低吞吐瓶颈

✅ 应用场景：

- 数学/逻辑问答类任务（如考试、作业、流程设计）
- 高并发推理需求平台，如问答机器人、大模型笔试系统、搜索问答引擎
- 低延迟交互式智能体，如AIGC协作助手、教育推理模型

**GLM-Z1-Rumination —— 下一代沉思模型，面向开放式复杂推理任务**

> **关键词：自主思考、动态验证、强化学习、Deep Research**

📌 模型定位：

- 能解决不确定性、多解性、高复杂度问题
- 构建“**提问—搜索—推理—验证—输出**”完整链条
- 可进行 **工具调用 + 搜索引擎整合 + 深度生成分析**

🧠 技术特点：

- **end-to-end 强化学习（RL）训练管线**，跨越搜索、思考、反馈验证全过程
- 模型可调用工具（如搜索引擎、代码运行器、文献数据库）
- 内建“反思—总结—修正”链式推理流程，**避免信息孤岛、单路径思维局限**
- 与人类研究者类比：如“AI 博士生”，可以处理需要检索、归纳、逻辑论证的长任务

示例场景：

- 科研写作、市场调研、政策评估等开放问题生成任务
- 多文档摘要、真伪验证、跨源知识对比任务
- 支持通过 [Z.ai](http://z.ai/) 平台体验，或部署至企业级智能体平台

**GLM-4-Air-0414 —— 强行动能力的基础模型，支持多任务智能体建设**

> **关键词：基础能力、工具调用优化、智能体能力增强、代码能力强化**

- GLM-4-Air-0414：高性能工具智能体基础
- GLM-4-Flash-250414：免费调用基础模型版本

![img_v3_02lc_6c098a21-84ca-41b8-a9e1-6638d2549d3g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_6c098a21-84ca-41b8-a9e1-6638d2549d3g.jpg)



**🌟 技术亮点：**

- 预训练使用 **15T 多源高质量数据**，强化逻辑、代码与推理能力
- 强调指令跟随、函数调用、代码生成与 Artifacts 操作
- 后训练融合 **拒绝采样 + 强化学习** 技术，提升任务完成准确性与泛化能力

📈 性能表现：

- 在工程代码、工具调用、搜索问答方面表现优异
- 与 GPT-4o、DeepSeek-V3（671B）部分任务表现持平
- HTML/CSS/JS/SVG 代码生成可实时预览，支持交互修改（已接入 [z.ai](http://z.ai/)）

![img_v3_02lc_8a9a154b-1ffa-4ac5-b414-97c7864c86fg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_8a9a154b-1ffa-4ac5-b414-97c7864c86fg.jpg)

💻 编程交互能力：

- 原生支持 HTML、CSS、JavaScript、SVG 等前端语言的实时代码生成与运行展示
- 可部署于代码生成平台、AIGC 设计辅助系统、低代码工具中

⚙️ 模块与接口：

- 与工具接口原生兼容，适合智能搜索、插件化助手、企业工具链集成
- 支持大模型原生开发 Agent 系统，形成完整**“感知—思考—行动”链**

🧪 示例任务：

- 用 HTML 模拟太阳系运动
- 用 SVG 展示 LLM 训练流程

![img_v3_02lc_08d26f48-2d0b-40af-ae40-1ceaa5609bbg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_08d26f48-2d0b-40af-ae40-1ceaa5609bbg.jpg)

- 用 JS 实现小游戏（如2048）

**[z.ai](http://z.ai/)** **上线**

智谱全新站点 **[z.ai](http://z.ai/)** 正式启用！该平台集成了对话、推理与沉思三类 GLM 模型，自今日起全面向全球用户免费开放使用。覆盖从文本生成、深度问答到多轮对话的智能场景，帮助用户快速进行智能问答、信息检索与研究任务。

**[z.ai](http://z.ai/)** 目前已上线三款开源模型：

- **GLM-4-32B（对话模型）**：具备强大代码生成能力，支持全新 Artifacts 功能，打造交互式开发体验
- **Z1-32B（推理模型）**：超强推理性能，在线体验最高达 **200 Tokens/秒** 的极速输出
- **Z1-Rumination-32B（沉思模型）**：驱动 Deep Research 能力的强大模型，免费开放

![img_v3_02lc_7e20442e-dfe0-44fe-bcdd-6139dbfb938g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_7e20442e-dfe0-44fe-bcdd-6139dbfb938g.jpg)



同时智谱宣布开始A股IPO...成为第一家正式启动IPO的大模型创业公司
`;

export const gpt41Update = `
OpenAI 以API 的形式发布了三个新模型：GPT-4.1、GPT-4.1 mini 和 GPT-4.1 nano。

这些模型的性能全面超越 GPT-4o 和 GPT-4o mini

在编码和指令跟踪方面均有显著提升。

拥有100 万个token的上下文

知识截止时间更新至 2024 年 6 月

![img_v3_02lc_d6516000-7d11-4090-9fa7-fca36773733g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_d6516000-7d11-4090-9fa7-fca36773733g.jpg)

![img_v3_02lc_a142cf12-4238-4875-9952-b3ef8a46910g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_a142cf12-4238-4875-9952-b3ef8a46910g.jpg)

- **GPT-4.1**：旗舰模型，在编码、指令遵循和长上下文理解方面表现最佳，适用于复杂任务。
- **GPT-4.1 mini**：小型模型，在多个基准测试中超越 GPT-4o，同时将延迟降低近一半，成本降低 83%，适合需要高效性能的场景。
- **GPT-4.1 nano**：OpenAI 首个超小型模型，速度最快、成本最低，拥有 100 万 token 上下文窗口，适用于低延迟任务如分类和自动补全。

![img_v3_02lc_c89c6e85-f37b-466f-b4b3-e79ec810df9g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_c89c6e85-f37b-466f-b4b3-e79ec810df9g.png)



**🛠️ 关键能力提升**

**1. 编程能力（Coding）**

- **SWE-bench Verified**：GPT-4.1 完成率 **54.6%**，大幅优于 GPT-4o（33.2%）和 GPT-4.5（38%）。
- 在 **Aider’s polyglot diff benchmark** 中（处理代码差异格式），GPT-4.1 diff 格式准确率达 **52.9%**，提升显著。
- **前端开发更优**：GPT-4.1 生成的 Web 页面在功能和美观性方面，80% 被人类评审偏好。

![img_v3_02lc_507d7226-ad3b-47ab-bf48-3e9b0988ad3g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_507d7226-ad3b-47ab-bf48-3e9b0988ad3g.jpg)

- **实际案例**：
  - **Windsurf**：代码接受率提升 60%，调用工具效率提升 30%。
  - **Qodo**：在 200 个真实 PR 上，GPT-4.1 在 55% 的场景下生成更优评审。



**2. 指令遵循能力（Instruction Following）**

- **MultiChallenge（Scale AI）**：GPT-4.1 得分 **38.3%**，比 GPT-4o 高 10.5%。
- **IFEval**：得分 87.4%，显著提升复杂指令的遵循能力。

![img_v3_02lc_4a7ffa55-c91d-45d9-bc4f-b6473325028g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_4a7ffa55-c91d-45d9-bc4f-b6473325028g.jpg)

- 更擅长处理：
  - 自定义格式（如 YAML、Markdown）
  - 否定指令
  - 多步顺序任务
  - “不确定就说不知道”类问题
- **实际案例**：
  - **Blue J**：税务场景中 GPT-4.1 的准确率提升 53%。
  - **Hex**：SQL 查询生成任务准确性提升 2 倍。



**3. 长上下文处理能力（Long Context）**

- 上下文窗口从 GPT-4o 的 12.8 万 token 扩展到 100 万 token，足以处理 8 个 React 代码库的完整内容。
- 在 Video-MME（长视频无字幕）基准测试中，GPT-4.1 得分 72.0%，比 GPT-4o（65.3%）提升 6.7%，在长上下文多模态任务中创下新纪录。
- OpenAI 还发布了两个新评估数据集：
  - **OpenAI-MRCR**：测试模型在长上下文中检索和区分多个相似信息的能力，GPT-4.1 在 100 万 token 上下文中的表现依然强劲。
  - **Graphwalks**：测试多跳推理能力，GPT-4.1 在广度优先搜索任务中得分 61.7%，与 o1 相当，远超 GPT-4o（41.7%）。

![img_v3_02lc_14d562bd-500e-4f35-b155-d62db6d38edg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_14d562bd-500e-4f35-b155-d62db6d38edg.jpg)

- Graphwalks BFS <128k 准确率 **61.7%**

  OpenAI-MRCR 1M token 两针准确率 **46.3%**

- **实际案例**：

  - **Thomson Reuters**：多文档法律审核准确率提升 17%
  - **Carlyle**：大文档中财务数据提取效率提升 50%



**4. 多模态能力（Vision）**

- 图表、数学视觉推理上优于 GPT-4o：
  - **MMMU**（图文理解）：GPT-4.1 得分 74.8%

![img_v3_02lc_0f020945-b107-4d89-872a-65603722765g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_0f020945-b107-4d89-872a-65603722765g.jpg)

- **MathVista**（视觉数学）：GPT-4.1 得分 72.2%

![img_v3_02lc_bee49526-a490-43bf-9ad0-d289f18717dg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_bee49526-a490-43bf-9ad0-d289f18717dg.jpg)

- **CharXiv**（科研图表）：GPT-4.1 得分 56.7%

![img_v3_02lc_64f7f356-afe7-4705-a7da-184104958a1g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_64f7f356-afe7-4705-a7da-184104958a1g.jpg)

- **Video-MME**（长视频理解）：GPT-4.1 得分 72.0%，领先行业

![img_v3_02lc_67089f6c-7c17-43bc-a4d0-d047617698dg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_67089f6c-7c17-43bc-a4d0-d047617698dg.jpg)



**💰 价格与性能**

![img_v3_02lc_d132dd0b-a49d-4720-8899-a2c903f2f23g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_d132dd0b-a49d-4720-8899-a2c903f2f23g.jpg)

- GPT-4.1 的中位查询价格比 GPT-4o 低 26%，GPT-4.1 nano 是 OpenAI 有史以来最便宜的模型。
- GPT-4.1 mini 的延迟比 GPT-4o 降低近一半，成本降低 83%，在智能评估中匹配或超越 GPT-4o。
- GPT-4.1 nano 在 12.8 万 token 上下文的查询中，首 token 响应时间通常少于 5 秒。

![img_v3_02lc_091ea1f0-2622-4216-8a20-01c02b4be7dg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_091ea1f0-2622-4216-8a20-01c02b4be7dg.jpg)



- 支持 prompt 缓存，最高可享 **75% 折扣**
- 适配 **Batch API** 可再打 5 折
- 🧾 与 GPT-4o 相比：
  - GPT‑4.1 性价比提升 26%
  - GPT-4.1 mini 性能接近但成本降低 83%
  - nano 是目前**最快+最便宜**模型



**现实世界的应用案例**

OpenAI 与多个合作伙伴测试了 GPT-4.1 系列模型，展示了其在现实世界任务中的表现：

- **编码**：
  - **Windsurf**：GPT-4.1 在内部编码基准测试中比 GPT-4o 高出 60%，代码更改首次审查通过率更高，工具调用效率提升 30%，重复编辑减少 50%。
  - **Qodo**：在 GitHub 拉取请求的代码审查任务中，GPT-4.1 在 55% 的案例中提供更好的建议，兼顾精确性和全面性。
- **指令遵循**：
  - **Blue J**：在复杂税务场景的内部基准测试中，GPT-4.1 比 GPT-4o 准确率高 53%，提升了税务研究的效率。
  - **Hex**：在 SQL 评估中，GPT-4.1 的准确率提升近 2 倍，尤其擅长处理大型模糊模式下的表选择，减少了手动调试。
- **长上下文**：
  - **Thomson Reuters**：GPT-4.1 在多文档法律审查任务中准确率比 GPT-4o 提高 17%，能准确识别文档间的矛盾条款和补充上下文。
  - **Carlyle**：在提取大型金融文档数据时，GPT-4.1 的检索能力提升 50%，克服了其他模型在针尖式检索和多跳推理中的局限。



**支持 AI 代理（Agents）**

GPT-4.1 系列模型在指令遵循和长上下文理解方面的改进，使其更适合构建 AI 代理（能够自主完成任务的系统）。结合 OpenAI 的 Responses API，开发者可以创建更可靠的代理，应用于：

- 软件工程：自动完成代码编写和调试。
- 大型文档分析：提取关键信息，生成洞察。
- 客户支持：处理复杂请求，减少人工干预。

**📌 后续变化**

- **GPT-4.5 Preview 将于 2025 年 7 月 14 日停用**
- GPT-4.1 将逐步成为开发者 API 的核心模型



发布会视频 翻译  

官方介绍：https://openai.com/index/gpt-4-1/
`;

export const openaiapi =`


OpenAI 以API 的形式发布了三个新模型：GPT-4.1、GPT-4.1 mini 和 GPT-4.1 nano。

这些模型的性能全面超越 GPT-4o 和 GPT-4o mini

在编码和指令跟踪方面均有显著提升。

拥有100 万个token的上下文

知识截止时间更新至 2024 年 6 月

![img_v3_02lc_d6516000-7d11-4090-9fa7-fca36773733g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_d6516000-7d11-4090-9fa7-fca36773733g.jpg)

![img_v3_02lc_a142cf12-4238-4875-9952-b3ef8a46910g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_a142cf12-4238-4875-9952-b3ef8a46910g.jpg)

- **GPT-4.1**：旗舰模型，在编码、指令遵循和长上下文理解方面表现最佳，适用于复杂任务。
- **GPT-4.1 mini**：小型模型，在多个基准测试中超越 GPT-4o，同时将延迟降低近一半，成本降低 83%，适合需要高效性能的场景。
- **GPT-4.1 nano**：OpenAI 首个超小型模型，速度最快、成本最低，拥有 100 万 token 上下文窗口，适用于低延迟任务如分类和自动补全。

![img_v3_02lc_c89c6e85-f37b-466f-b4b3-e79ec810df9g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_c89c6e85-f37b-466f-b4b3-e79ec810df9g.png)



**🛠️ 关键能力提升**

**1. 编程能力（Coding）**

- **SWE-bench Verified**：GPT-4.1 完成率 **54.6%**，大幅优于 GPT-4o（33.2%）和 GPT-4.5（38%）。
- 在 **Aider’s polyglot diff benchmark** 中（处理代码差异格式），GPT-4.1 diff 格式准确率达 **52.9%**，提升显著。
- **前端开发更优**：GPT-4.1 生成的 Web 页面在功能和美观性方面，80% 被人类评审偏好。

![img_v3_02lc_507d7226-ad3b-47ab-bf48-3e9b0988ad3g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_507d7226-ad3b-47ab-bf48-3e9b0988ad3g.jpg)

- **实际案例**：
  - **Windsurf**：代码接受率提升 60%，调用工具效率提升 30%。
  - **Qodo**：在 200 个真实 PR 上，GPT-4.1 在 55% 的场景下生成更优评审。



**2. 指令遵循能力（Instruction Following）**

- **MultiChallenge（Scale AI）**：GPT-4.1 得分 **38.3%**，比 GPT-4o 高 10.5%。
- **IFEval**：得分 87.4%，显著提升复杂指令的遵循能力。

![img_v3_02lc_4a7ffa55-c91d-45d9-bc4f-b6473325028g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_4a7ffa55-c91d-45d9-bc4f-b6473325028g.jpg)

- 更擅长处理：
  - 自定义格式（如 YAML、Markdown）
  - 否定指令
  - 多步顺序任务
  - “不确定就说不知道”类问题
- **实际案例**：
  - **Blue J**：税务场景中 GPT-4.1 的准确率提升 53%。
  - **Hex**：SQL 查询生成任务准确性提升 2 倍。



**3. 长上下文处理能力（Long Context）**

- 上下文窗口从 GPT-4o 的 12.8 万 token 扩展到 100 万 token，足以处理 8 个 React 代码库的完整内容。
- 在 Video-MME（长视频无字幕）基准测试中，GPT-4.1 得分 72.0%，比 GPT-4o（65.3%）提升 6.7%，在长上下文多模态任务中创下新纪录。
- OpenAI 还发布了两个新评估数据集：
  - **OpenAI-MRCR**：测试模型在长上下文中检索和区分多个相似信息的能力，GPT-4.1 在 100 万 token 上下文中的表现依然强劲。
  - **Graphwalks**：测试多跳推理能力，GPT-4.1 在广度优先搜索任务中得分 61.7%，与 o1 相当，远超 GPT-4o（41.7%）。

![img_v3_02lc_14d562bd-500e-4f35-b155-d62db6d38edg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_14d562bd-500e-4f35-b155-d62db6d38edg.jpg)

- Graphwalks BFS <128k 准确率 **61.7%**

  OpenAI-MRCR 1M token 两针准确率 **46.3%**

- **实际案例**：

  - **Thomson Reuters**：多文档法律审核准确率提升 17%
  - **Carlyle**：大文档中财务数据提取效率提升 50%



**4. 多模态能力（Vision）**

- 图表、数学视觉推理上优于 GPT-4o：
  - **MMMU**（图文理解）：GPT-4.1 得分 74.8%

![img_v3_02lc_0f020945-b107-4d89-872a-65603722765g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_0f020945-b107-4d89-872a-65603722765g.jpg)

- **MathVista**（视觉数学）：GPT-4.1 得分 72.2%

![img_v3_02lc_bee49526-a490-43bf-9ad0-d289f18717dg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_bee49526-a490-43bf-9ad0-d289f18717dg.jpg)

- **CharXiv**（科研图表）：GPT-4.1 得分 56.7%

![img_v3_02lc_64f7f356-afe7-4705-a7da-184104958a1g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_64f7f356-afe7-4705-a7da-184104958a1g.jpg)

- **Video-MME**（长视频理解）：GPT-4.1 得分 72.0%，领先行业

![img_v3_02lc_67089f6c-7c17-43bc-a4d0-d047617698dg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_67089f6c-7c17-43bc-a4d0-d047617698dg.jpg)



**💰 价格与性能**

![img_v3_02lc_d132dd0b-a49d-4720-8899-a2c903f2f23g](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_d132dd0b-a49d-4720-8899-a2c903f2f23g.jpg)

- GPT-4.1 的中位查询价格比 GPT-4o 低 26%，GPT-4.1 nano 是 OpenAI 有史以来最便宜的模型。
- GPT-4.1 mini 的延迟比 GPT-4o 降低近一半，成本降低 83%，在智能评估中匹配或超越 GPT-4o。
- GPT-4.1 nano 在 12.8 万 token 上下文的查询中，首 token 响应时间通常少于 5 秒。

![img_v3_02lc_091ea1f0-2622-4216-8a20-01c02b4be7dg](https://jsd.onmicrosoft.cn/gh/yy0691/img-bed@main/Blog/AiNews/img_v3_02lc_091ea1f0-2622-4216-8a20-01c02b4be7dg.jpg)



- 支持 prompt 缓存，最高可享 **75% 折扣**
- 适配 **Batch API** 可再打 5 折
- 🧾 与 GPT-4o 相比：
  - GPT‑4.1 性价比提升 26%
  - GPT-4.1 mini 性能接近但成本降低 83%
  - nano 是目前**最快+最便宜**模型



**现实世界的应用案例**

OpenAI 与多个合作伙伴测试了 GPT-4.1 系列模型，展示了其在现实世界任务中的表现：

- **编码**：
  - **Windsurf**：GPT-4.1 在内部编码基准测试中比 GPT-4o 高出 60%，代码更改首次审查通过率更高，工具调用效率提升 30%，重复编辑减少 50%。
  - **Qodo**：在 GitHub 拉取请求的代码审查任务中，GPT-4.1 在 55% 的案例中提供更好的建议，兼顾精确性和全面性。
- **指令遵循**：
  - **Blue J**：在复杂税务场景的内部基准测试中，GPT-4.1 比 GPT-4o 准确率高 53%，提升了税务研究的效率。
  - **Hex**：在 SQL 评估中，GPT-4.1 的准确率提升近 2 倍，尤其擅长处理大型模糊模式下的表选择，减少了手动调试。
- **长上下文**：
  - **Thomson Reuters**：GPT-4.1 在多文档法律审查任务中准确率比 GPT-4o 提高 17%，能准确识别文档间的矛盾条款和补充上下文。
  - **Carlyle**：在提取大型金融文档数据时，GPT-4.1 的检索能力提升 50%，克服了其他模型在针尖式检索和多跳推理中的局限。



**支持 AI 代理（Agents）**

GPT-4.1 系列模型在指令遵循和长上下文理解方面的改进，使其更适合构建 AI 代理（能够自主完成任务的系统）。结合 OpenAI 的 Responses API，开发者可以创建更可靠的代理，应用于：

- 软件工程：自动完成代码编写和调试。
- 大型文档分析：提取关键信息，生成洞察。
- 客户支持：处理复杂请求，减少人工干预。

**📌 后续变化**

- **GPT-4.5 Preview 将于 2025 年 7 月 14 日停用**
- GPT-4.1 将逐步成为开发者 API 的核心模型



发布会视频 翻译  

官方介绍：https://openai.com/index/gpt-4-1/
`

